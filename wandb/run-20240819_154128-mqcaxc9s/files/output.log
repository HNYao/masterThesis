2024-08-19 15:41:32,282 [Worker 0] Is distributed: False
2024-08-19 15:41:32,282 [Process: 0] Starting training
2024-08-19 15:41:32,282 [Process: 0] EPOCH 1:
2024-08-19 15:41:32,285 [Worker 0] Loss fn: focal - FocalLoss(), Rank 0 - True
2024-08-19 15:41:33,719 [Process: 0] Synchronize training processes
2024-08-19 15:41:33,719 [Process: 0] Evaluating...
[Worker 0] Is distributed: False
[Process: 0] Starting training
[Process: 0] EPOCH 1:
[Worker 0] Loss fn: focal - FocalLoss(), Rank 0 - True
['To Front of the normal monitor, there is a the normal keyboard', 'the blue phone is at the Back of the normal phone']
------list
['To Front of the normal monitor, there is a the normal keyboard', 'the blue phone is at the Back of the normal phone']
<class 'str'>
<class 'str'>
----x_geo shape: torch.Size([2, 16, 512])
----x_rgb shape: torch.Size([2, 16, 480, 640])
-----scene_pcs shape: torch.Size([2, 512, 3])
-----align shape: torch.Size([2, 16, 512])
------x shape: torch.Size([2, 35, 512])
------fusion x shape: torch.Size([2, 4, 512])
------target shape: torch.Size([2, 512, 4])
tensor([[[0.2028, 0.3592, 0.1945,  ..., 0.1251, 0.4740, 0.1963],
         [0.3724, 0.2667, 0.1582,  ..., 0.1394, 0.1753, 0.4111],
         [0.2220, 0.1966, 0.4491,  ..., 0.5495, 0.1753, 0.1963],
         [0.2028, 0.1774, 0.1982,  ..., 0.1860, 0.1753, 0.1963]],
        [[0.3022, 0.1658, 0.5318,  ..., 0.2739, 0.2172, 0.1463],
         [0.1963, 0.4420, 0.0963,  ..., 0.3728, 0.2172, 0.2151],
         [0.1502, 0.2115, 0.0963,  ..., 0.1767, 0.3485, 0.1463],
         [0.3513, 0.1806, 0.2755,  ..., 0.1767, 0.2172, 0.4923]]],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
outputs shape: torch.Size([2, 4, 512])
mask shape: torch.Size([2, 512, 4])
["the orange lamp is on the normal eraser's Front side", "the normal printer is on the normal plant's Front Right side"]
------list
["the orange lamp is on the normal eraser's Front side", "the normal printer is on the normal plant's Front Right side"]
<class 'str'>
<class 'str'>
----x_geo shape: torch.Size([2, 16, 512])
----x_rgb shape: torch.Size([2, 16, 480, 640])
-----scene_pcs shape: torch.Size([2, 512, 3])
-----align shape: torch.Size([2, 16, 512])
------x shape: torch.Size([2, 35, 512])
------fusion x shape: torch.Size([2, 4, 512])
------target shape: torch.Size([2, 512, 4])
tensor([[[0.2778, 0.2283, 0.2226,  ..., 0.2713, 0.1774, 0.1935],
         [0.2613, 0.2435, 0.1894,  ..., 0.2826, 0.2217, 0.2057],
         [0.2159, 0.2471, 0.1983,  ..., 0.2162, 0.2912, 0.1796],
         [0.2449, 0.2811, 0.3897,  ..., 0.2300, 0.3097, 0.4213]],
        [[0.2610, 0.2476, 0.2700,  ..., 0.3054, 0.2385, 0.2367],
         [0.2309, 0.2585, 0.2519,  ..., 0.2521, 0.2665, 0.2783],
         [0.1981, 0.2195, 0.1898,  ..., 0.2037, 0.2385, 0.2588],
         [0.3100, 0.2744, 0.2882,  ..., 0.2388, 0.2565, 0.2261]]],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
outputs shape: torch.Size([2, 4, 512])
mask shape: torch.Size([2, 512, 4])
[Process: 0] Synchronize training processes
[Process: 0] Evaluating...
(2, 512, 3)