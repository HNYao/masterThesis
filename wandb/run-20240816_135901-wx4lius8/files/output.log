2024-08-16 13:59:06,717 [Worker 0] Is distributed: False
2024-08-16 13:59:06,717 [Process: 0] Starting training
2024-08-16 13:59:06,717 [Process: 0] EPOCH 1:
2024-08-16 13:59:06,720 [Worker 0] Loss fn: soft_dice - SoftDiceLoss(), Rank 0 - True
[Worker 0] Is distributed: False
[Process: 0] Starting training
[Process: 0] EPOCH 1:
[Worker 0] Loss fn: soft_dice - SoftDiceLoss(), Rank 0 - True
['To Front of the normal monitor, there is a the normal keyboard', 'the blue phone is at the Back of the normal phone']
------list
['To Front of the normal monitor, there is a the normal keyboard', 'the blue phone is at the Back of the normal phone']
<class 'str'>
<class 'str'>
----x_geo shape: torch.Size([2, 16, 4096])
----x_rgb shape: torch.Size([2, 16, 480, 640])
-----scene_pcs shape: torch.Size([2, 4096, 3])
-----align shape: torch.Size([2, 16, 4096])
------x shape: torch.Size([2, 35, 4096])
------fusion x shape: torch.Size([2, 4, 4096])
------target shape: torch.Size([2, 4096, 4])
tensor([[[0.2288, 0.2102, 0.2691,  ..., 0.3613, 0.3844, 0.3568],
         [0.2360, 0.3695, 0.2254,  ..., 0.2129, 0.2029, 0.2303],
         [0.3065, 0.2102, 0.2067,  ..., 0.2129, 0.2029, 0.2065],
         [0.2288, 0.2102, 0.2988,  ..., 0.2129, 0.2099, 0.2065]],
        [[0.2659, 0.2759, 0.2439,  ..., 0.2364, 0.2260, 0.2454],
         [0.2447, 0.2414, 0.2683,  ..., 0.2658, 0.2260, 0.2454],
         [0.2447, 0.2414, 0.2439,  ..., 0.2615, 0.3221, 0.2638],
         [0.2447, 0.2414, 0.2439,  ..., 0.2364, 0.2260, 0.2454]]],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
outputs shape: torch.Size([2, 4, 4096])
mask shape: torch.Size([2, 4096, 4])
shape of inputs: torch.Size([2, 4, 4096])
shape of targets: torch.Size([2, 4, 4096])
2024-08-16 13:59:09,287 [Process: 0] Synchronize training processes
2024-08-16 13:59:09,288 [Process: 0] Evaluating...
2024-08-16 13:59:09,290 [Process: 0] EPOCH 2:
2024-08-16 13:59:09,292 [Worker 0] Loss fn: soft_dice - SoftDiceLoss(), Rank 0 - True
["the orange lamp is on the normal eraser's Front side", "the normal printer is on the normal plant's Front Right side"]
------list
["the orange lamp is on the normal eraser's Front side", "the normal printer is on the normal plant's Front Right side"]
<class 'str'>
<class 'str'>
----x_geo shape: torch.Size([2, 16, 4096])
----x_rgb shape: torch.Size([2, 16, 480, 640])
-----scene_pcs shape: torch.Size([2, 4096, 3])
-----align shape: torch.Size([2, 16, 4096])
------x shape: torch.Size([2, 35, 4096])
------fusion x shape: torch.Size([2, 4, 4096])
------target shape: torch.Size([2, 4096, 4])
tensor([[[0.1327, 0.1823, 0.2500,  ..., 0.2028, 0.1906, 0.2500],
         [0.5577, 0.3805, 0.2500,  ..., 0.3915, 0.4281, 0.2500],
         [0.1327, 0.1823, 0.2500,  ..., 0.2028, 0.1906, 0.2500],
         [0.1768, 0.2549, 0.2500,  ..., 0.2028, 0.1906, 0.2500]],
        [[0.3345, 0.2149, 0.2082,  ..., 0.2025, 0.1228, 0.4348],
         [0.1415, 0.2149, 0.1067,  ..., 0.1714, 0.1041, 0.1259],
         [0.3825, 0.3554, 0.3550,  ..., 0.4030, 0.5636, 0.2335],
         [0.1415, 0.2149, 0.3301,  ..., 0.2231, 0.2096, 0.2058]]],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
outputs shape: torch.Size([2, 4, 4096])
mask shape: torch.Size([2, 4096, 4])
shape of inputs: torch.Size([2, 4, 4096])
shape of targets: torch.Size([2, 4, 4096])
[Process: 0] Synchronize training processes
[Process: 0] Evaluating...
[Process: 0] EPOCH 2:
[Worker 0] Loss fn: soft_dice - SoftDiceLoss(), Rank 0 - True
['To Front of the normal monitor, there is a the normal keyboard', 'the blue phone is at the Back of the normal phone']
------list
['To Front of the normal monitor, there is a the normal keyboard', 'the blue phone is at the Back of the normal phone']
<class 'str'>
<class 'str'>
----x_geo shape: torch.Size([2, 16, 4096])
----x_rgb shape: torch.Size([2, 16, 480, 640])
-----scene_pcs shape: torch.Size([2, 4096, 3])
-----align shape: torch.Size([2, 16, 4096])
------x shape: torch.Size([2, 35, 4096])
------fusion x shape: torch.Size([2, 4, 4096])
------target shape: torch.Size([2, 4096, 4])
tensor([[[0.3229, 0.3146, 0.3269,  ..., 0.3065, 0.2351, 0.3404],
         [0.2184, 0.1742, 0.2304,  ..., 0.1880, 0.2351, 0.1702],
         [0.2070, 0.1837, 0.2133,  ..., 0.1880, 0.2947, 0.2082],
         [0.2517, 0.3275, 0.2295,  ..., 0.3174, 0.2351, 0.2812]],
        [[0.2311, 0.2243, 0.2255,  ..., 0.2304, 0.2455, 0.3024],
         [0.3067, 0.3081, 0.2591,  ..., 0.2324, 0.2636, 0.2612],
         [0.2311, 0.2243, 0.2187,  ..., 0.2304, 0.2455, 0.2125],
         [0.2311, 0.2434, 0.2967,  ..., 0.3068, 0.2455, 0.2239]]],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
outputs shape: torch.Size([2, 4, 4096])
mask shape: torch.Size([2, 4096, 4])
shape of inputs: torch.Size([2, 4, 4096])
shape of targets: torch.Size([2, 4, 4096])
2024-08-16 13:59:11,220 [Process: 0] Synchronize training processes
2024-08-16 13:59:11,221 [Process: 0] Evaluating...
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/run.py", line 31, in main
    trainer.train()
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/trainer/trainer.py", line 355, in train
    self.model.inference()
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/models/GeoL.py", line 98, in inference
    point_cloud.colors = o3d.utility.Vector3dVector(colors[0].cpu.numpy())
AttributeError: 'builtin_function_or_method' object has no attribute 'numpy'
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
["the orange lamp is on the normal eraser's Front side", "the normal printer is on the normal plant's Front Right side"]
------list
["the orange lamp is on the normal eraser's Front side", "the normal printer is on the normal plant's Front Right side"]
<class 'str'>
<class 'str'>
----x_geo shape: torch.Size([2, 16, 4096])
----x_rgb shape: torch.Size([2, 16, 480, 640])
-----scene_pcs shape: torch.Size([2, 4096, 3])
-----align shape: torch.Size([2, 16, 4096])
------x shape: torch.Size([2, 35, 4096])
------fusion x shape: torch.Size([2, 4, 4096])
------target shape: torch.Size([2, 4096, 4])
tensor([[[0.3373, 0.0809, 0.2044,  ..., 0.2499, 0.1242, 0.1697],
         [0.2108, 0.3984, 0.2181,  ..., 0.2499, 0.1242, 0.1697],
         [0.2108, 0.2129, 0.2233,  ..., 0.2503, 0.3654, 0.4908],
         [0.2412, 0.3078, 0.3543,  ..., 0.2499, 0.3862, 0.1697]],
        [[0.2500, 0.6986, 0.1227,  ..., 0.4186, 0.6386, 0.1744],
         [0.2500, 0.0368, 0.0701,  ..., 0.2665, 0.1179, 0.4767],
         [0.2500, 0.0368, 0.0701,  ..., 0.1355, 0.1179, 0.1744],
         [0.2500, 0.2278, 0.7371,  ..., 0.1794, 0.1256, 0.1744]]],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
outputs shape: torch.Size([2, 4, 4096])
mask shape: torch.Size([2, 4096, 4])
shape of inputs: torch.Size([2, 4, 4096])
shape of targets: torch.Size([2, 4, 4096])
[Process: 0] Synchronize training processes
[Process: 0] Evaluating...