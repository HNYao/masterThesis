2024-08-19 11:00:21,508 [Worker 0] Is distributed: False
2024-08-19 11:00:21,508 [Process: 0] Starting training
2024-08-19 11:00:21,508 [Process: 0] EPOCH 1:
2024-08-19 11:00:21,512 [Worker 0] Loss fn: focal - FocalLoss(), Rank 0 - True
2024-08-19 11:00:23,236 [Process: 0] Synchronize training processes
2024-08-19 11:00:23,236 [Process: 0] Evaluating...
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/run.py", line 31, in main
    trainer.train()
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/trainer/trainer.py", line 356, in train
    self.model.inference_heatmap_4cls()
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/models/GeoL.py", line 135, in inference_heatmap_4cls
    colors = camp(normalized_class_1_feat)[:,:,3]
  File "/home/stud/zhoy/anaconda3/envs/o2o/lib/python3.8/site-packages/matplotlib/colors.py", line 712, in __call__
    xa = np.array(X, copy=True)
  File "/home/stud/zhoy/anaconda3/envs/o2o/lib/python3.8/site-packages/torch/_tensor.py", line 970, in __array__
    return self.numpy()
RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[Worker 0] Is distributed: False
[Process: 0] Starting training
[Process: 0] EPOCH 1:
[Worker 0] Loss fn: focal - FocalLoss(), Rank 0 - True
['To Front of the normal monitor, there is a the normal keyboard', 'the blue phone is at the Back of the normal phone']
------list
['To Front of the normal monitor, there is a the normal keyboard', 'the blue phone is at the Back of the normal phone']
<class 'str'>
<class 'str'>
----x_geo shape: torch.Size([2, 16, 512])
----x_rgb shape: torch.Size([2, 16, 480, 640])
-----scene_pcs shape: torch.Size([2, 512, 3])
-----align shape: torch.Size([2, 16, 512])
------x shape: torch.Size([2, 35, 512])
------fusion x shape: torch.Size([2, 4, 512])
------target shape: torch.Size([2, 512, 4])
tensor([[[0.2013, 0.3420, 0.1496,  ..., 0.1481, 0.4452, 0.1980],
         [0.3961, 0.3088, 0.1496,  ..., 0.1420, 0.1849, 0.4061],
         [0.2013, 0.1928, 0.5388,  ..., 0.5084, 0.1849, 0.1980],
         [0.2013, 0.1564, 0.1620,  ..., 0.2015, 0.1849, 0.1980]],
        [[0.3098, 0.1502, 0.6037,  ..., 0.2301, 0.2239, 0.1630],
         [0.1867, 0.4153, 0.0751,  ..., 0.3520, 0.2239, 0.2199],
         [0.1668, 0.2519, 0.0751,  ..., 0.2089, 0.3282, 0.1630],
         [0.3367, 0.1825, 0.2462,  ..., 0.2089, 0.2239, 0.4541]]],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
outputs shape: torch.Size([2, 4, 512])
mask shape: torch.Size([2, 512, 4])
["the orange lamp is on the normal eraser's Front side", "the normal printer is on the normal plant's Front Right side"]
------list
["the orange lamp is on the normal eraser's Front side", "the normal printer is on the normal plant's Front Right side"]
<class 'str'>
<class 'str'>
----x_geo shape: torch.Size([2, 16, 512])
----x_rgb shape: torch.Size([2, 16, 480, 640])
-----scene_pcs shape: torch.Size([2, 512, 3])
-----align shape: torch.Size([2, 16, 512])
------x shape: torch.Size([2, 35, 512])
------fusion x shape: torch.Size([2, 4, 512])
------target shape: torch.Size([2, 512, 4])
tensor([[[0.2685, 0.2215, 0.2845,  ..., 0.2806, 0.2942, 0.2480],
         [0.2832, 0.2833, 0.2911,  ..., 0.2611, 0.2900, 0.3026],
         [0.2242, 0.2215, 0.2122,  ..., 0.1738, 0.2026, 0.1752],
         [0.2242, 0.2738, 0.2122,  ..., 0.2845, 0.2132, 0.2741]],
        [[0.2810, 0.2416, 0.2668,  ..., 0.0838, 0.0891, 0.2884],
         [0.2097, 0.2370, 0.2370,  ..., 0.0838, 0.2256, 0.2858],
         [0.2297, 0.1854, 0.2370,  ..., 0.7485, 0.5962, 0.1879],
         [0.2796, 0.3360, 0.2592,  ..., 0.0838, 0.0891, 0.2380]]],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
outputs shape: torch.Size([2, 4, 512])
mask shape: torch.Size([2, 512, 4])
[Process: 0] Synchronize training processes
[Process: 0] Evaluating...