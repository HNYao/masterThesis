import torch
from torch.utils.data import DataLoader, Subset, random_split
from metrics.dataset_factory import *
from metrics.utils import *
from GeoL_net.gpt.gpt import *

def gpt_metrics(
        dataset=BlendprocDesktopDataset(),
        sample_datasize=10,
        gpt_version = "gpt-4o-mini",
        process_metric_func = process_direction_metrics
):
    
    num_sample = sample_datasize
    indices = torch.arange(num_sample)
    subset = Subset(dataset, indices)
    dataloader = DataLoader(subset, batch_size=1, shuffle=False, num_workers=0)

    # intialize the model



    is_success_result = []
    is_mask_result = []

    test_sum = 0
    for data_batch in dataloader:

        img_path = data_batch["rgb_image_file_path"][0]
        image = Image.open(img_path)
        object_to_place = data_batch["obj_to_place"][0]
        direction = data_batch["directions"][0]
        anchor_obj_name = data_batch["ref_objects"][0]

        bbox = chatgpt_object_placement_bbox(
            gpt_version=gpt_version,
            image_path=img_path,
            prompts_obj_place=object_to_place,
            prompts_direction=direction,
            prompts_anchor_obj=anchor_obj_name,
        )

        if bbox is None:
            print("Failed to find position")
            is_success = [False, False, False, False, False]
            is_mask = [False, False, False, False, False]
            test_sum+=1
        
        else:

            image = np.array(image)
            updated_img = sample_points_in_bbox(image, bbox, n=5)

            is_success, is_mask = process_metric_func(
                image_sampled_point=updated_img, 
                depth_path=data_batch["depth_img_file_path"][0],
                mask_file_path = data_batch["mask_file_path"][0],               
                )
        
            is_success_result += is_success

            is_mask_result += is_mask
            test_sum+=1
        print('test_sum:', test_sum)
        print("current success rate:", sum(is_success_result) / len(is_success_result) * 100, "%")
        print("current mask rate:", sum(is_mask_result) / len(is_mask_result) * 100, "%")

    
    print("final success rate:", sum(is_success_result) / len(is_success_result)*100, "%")
    print("final mask rate:", sum(is_mask_result) / len(is_mask_result)*100, "%")

if __name__ == '__main__':
    dataset = realworld_dataset()
    total_resualt = gpt_metrics(
        dataset, 
        sample_datasize=len(dataset), 
        gpt_version="gpt-4o", 
        process_metric_func=rw_process_success_metrics)