[Worker 0] Is distributed: False
[Process: 0] Starting training
[Process: 0] EPOCH 1:
[Worker 0] Loss fn: soft_dice - SoftDiceLoss(), Rank 0 - True
batch: {'fps_points_scene': tensor([[[-1908.0001, -1979.8685,   391.2253],
         [ 1013.1855,   769.6771,   390.8845],
         [ 1896.7266, -1979.8685,   391.2253],
         ...,
         [  473.6666, -1558.4069,   391.0715],
         [-1228.4409, -1947.9481,   391.4156],
         [  305.1682,   662.2380,   391.5552]],
        [[-1908.0001, -1979.8685,   391.2253],
         [ 1013.1855,   769.6771,   390.8845],
         [ 1896.7266, -1979.8685,   391.2253],
         ...,
         [  782.7766, -1634.5261,   391.4821],
         [-1026.4163, -1243.0698,   391.3244],
         [  911.4598, -1309.8785,   391.2178]]], device='cuda:0'), 'fps_colors_scene': tensor([[[0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.],
         ...,
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]],
        [[0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.],
         ...,
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]]], device='cuda:0'), 'ref_center': tensor([[-134.0636, -254.3283, 1401.5000],
        [-420.2566,  -67.4510, 1415.5000]], device='cuda:0'), 'colors_modified': tensor([[[0., 0., 0., 1.],
         [0., 0., 0., 1.],
         [0., 0., 0., 1.],
         ...,
         [0., 0., 0., 1.],
         [0., 0., 0., 1.],
         [0., 0., 0., 1.]],
        [[0., 0., 0., 1.],
         [0., 0., 0., 1.],
         [0., 0., 0., 1.],
         ...,
         [0., 0., 0., 1.],
         [0., 0., 0., 1.],
         [0., 0., 0., 1.]]], device='cuda:0'), 'ref_obj': ['the normal monitor', 'the normal phone'], 'target_query': ['To Front of the normal monitor, there is a the normal keyboard', 'the blue phone is at the Back of the normal phone'], 'image': tensor([[[[104., 104.,  80.],
          [109., 109.,  85.],
          [106., 108.,  86.],
          ...,
          [ 78.,  82.,  59.],
          [ 81.,  84.,  63.],
          [ 78.,  83.,  63.]],
         [[102., 102.,  78.],
          [106., 106.,  82.],
          [105., 107.,  85.],
          ...,
          [ 78.,  82.,  59.],
          [ 75.,  80.,  58.],
          [ 83.,  88.,  66.]],
         [[106., 105.,  84.],
          [107., 106.,  85.],
          [ 98.,  97.,  77.],
          ...,
          [ 96., 100.,  75.],
          [104., 109.,  86.],
          [110., 115.,  92.]],
         ...,
         [[ 81.,  83.,  78.],
          [ 78.,  80.,  75.],
          [ 76.,  78.,  73.],
          ...,
          [120., 104.,  89.],
          [117., 104.,  88.],
          [115., 102.,  86.]],
         [[ 76.,  78.,  73.],
          [ 77.,  79.,  74.],
          [ 78.,  80.,  75.],
          ...,
          [123., 107.,  91.],
          [117., 104.,  88.],
          [112.,  99.,  83.]],
         [[ 82.,  84.,  79.],
          [ 81.,  83.,  78.],
          [ 79.,  81.,  76.],
          ...,
          [127., 111.,  95.],
          [125., 112.,  96.],
          [123., 110.,  94.]]],
        [[[133., 110.,  92.],
          [138., 115.,  97.],
          [134., 111.,  93.],
          ...,
          [130., 109.,  90.],
          [127., 106.,  89.],
          [124., 103.,  86.]],
         [[136., 113.,  95.],
          [140., 117.,  99.],
          [135., 112.,  94.],
          ...,
          [134., 113.,  94.],
          [134., 113.,  96.],
          [135., 114.,  97.]],
         [[134., 111.,  93.],
          [137., 114.,  96.],
          [135., 112.,  94.],
          ...,
          [127., 106.,  89.],
          [126., 105.,  88.],
          [128., 107.,  90.]],
         ...,
         [[129., 110.,  93.],
          [129., 110.,  93.],
          [129., 110.,  93.],
          ...,
          [133., 110.,  92.],
          [134., 111.,  93.],
          [135., 112.,  94.]],
         [[134., 115.,  98.],
          [132., 113.,  96.],
          [131., 112.,  95.],
          ...,
          [135., 112.,  94.],
          [133., 110.,  94.],
          [131., 108.,  92.]],
         [[146., 127., 110.],
          [143., 124., 107.],
          [137., 118., 101.],
          ...,
          [138., 115.,  97.],
          [137., 114.,  98.],
          [135., 112.,  96.]]]], device='cuda:0'), 'mask': tensor([[[3519., 3519., 3519.,  ..., 3519., 3519., 3519.],
         [3513., 3513., 3513.,  ..., 3513., 3513., 3513.],
         [3506., 3506., 3506.,  ..., 3506., 3506., 3506.],
         ...,
         [1873., 1873., 1873.,  ..., 1873., 1873., 1873.],
         [1871., 1871., 1871.,  ..., 1871., 1871., 1871.],
         [1869., 1869., 1869.,  ..., 1869., 1869., 1869.]],
        [[3519., 3519., 3519.,  ..., 3519., 3519., 3519.],
         [3513., 3513., 3513.,  ..., 3513., 3513., 3513.],
         [3506., 3506., 3506.,  ..., 3506., 3506., 3506.],
         ...,
         [1873., 1873., 1873.,  ..., 1873., 1873., 1873.],
         [1871., 1871., 1871.,  ..., 1871., 1871., 1871.],
         [1869., 1869., 1869.,  ..., 1869., 1869., 1869.]]], device='cuda:0')}
shape of recept: torch.Size([2, 480, 640, 3])
2024-08-13 16:51:22,233 [Worker 0] Is distributed: False
2024-08-13 16:51:22,234 [Process: 0] Starting training
2024-08-13 16:51:22,234 [Process: 0] EPOCH 1:
2024-08-13 16:51:22,236 [Worker 0] Loss fn: soft_dice - SoftDiceLoss(), Rank 0 - True
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/run.py", line 31, in main
    trainer.train()
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/trainer/trainer.py", line 340, in train
    avg_loss, avg_metrics = self.train_one_epoch(epoch)
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/trainer/trainer.py", line 199, in train_one_epoch
    outputs = self.model(batch=batch)["affordance"].squeeze(1)
  File "/home/stud/zhoy/anaconda3/envs/o2o/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/models/clip_unet.py", line 317, in forward
    x = self.forward_encoder(receptacle, target)
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/models/clip_unet.py", line 293, in forward_encoder
    x, x_im_feats = self.clip(image)
  File "/home/stud/zhoy/anaconda3/envs/o2o/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/stud/zhoy/MasterThesis_zhoy/GeoL_net/models/encoders/clip_encoder.py", line 82, in forward
    batch = self.preprocess(batch)
  File "/home/stud/zhoy/anaconda3/envs/o2o/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/stud/zhoy/anaconda3/envs/o2o/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/stud/zhoy/anaconda3/envs/o2o/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 277, in forward
    return F.normalize(tensor, self.mean, self.std, self.inplace)
  File "/home/stud/zhoy/anaconda3/envs/o2o/lib/python3.8/site-packages/torchvision/transforms/functional.py", line 363, in normalize
    return F_t.normalize(tensor, mean=mean, std=std, inplace=inplace)
  File "/home/stud/zhoy/anaconda3/envs/o2o/lib/python3.8/site-packages/torchvision/transforms/_functional_tensor.py", line 928, in normalize
    return tensor.sub_(mean).div_(std)
RuntimeError: The size of tensor a (480) must match the size of tensor b (3) at non-singleton dimension 1
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.